// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: api/v0alpha/lms.proto

package com.tcn.cloud.api.api.v0alpha;

public interface BulkWebEntrypointProcessOrBuilder extends
    // @@protoc_insertion_point(interface_extends:api.v0alpha.BulkWebEntrypointProcess)
    com.google.protobuf.MessageOrBuilder {

  /**
   * <pre>
   * the requests to make, in order, to access priliminary data needed
   * to make the bulk data action part of the entrypoint.
   * the user is expected to specify which values need to be saved
   * in the HttpReq.named_response_values map.
   * </pre>
   *
   * <code>repeated .api.v0alpha.HttpReq preliminary_requests = 2 [json_name = "preliminaryRequests"];</code>
   */
  java.util.List<com.tcn.cloud.api.api.v0alpha.HttpReq> 
      getPreliminaryRequestsList();
  /**
   * <pre>
   * the requests to make, in order, to access priliminary data needed
   * to make the bulk data action part of the entrypoint.
   * the user is expected to specify which values need to be saved
   * in the HttpReq.named_response_values map.
   * </pre>
   *
   * <code>repeated .api.v0alpha.HttpReq preliminary_requests = 2 [json_name = "preliminaryRequests"];</code>
   */
  com.tcn.cloud.api.api.v0alpha.HttpReq getPreliminaryRequests(int index);
  /**
   * <pre>
   * the requests to make, in order, to access priliminary data needed
   * to make the bulk data action part of the entrypoint.
   * the user is expected to specify which values need to be saved
   * in the HttpReq.named_response_values map.
   * </pre>
   *
   * <code>repeated .api.v0alpha.HttpReq preliminary_requests = 2 [json_name = "preliminaryRequests"];</code>
   */
  int getPreliminaryRequestsCount();
  /**
   * <pre>
   * the requests to make, in order, to access priliminary data needed
   * to make the bulk data action part of the entrypoint.
   * the user is expected to specify which values need to be saved
   * in the HttpReq.named_response_values map.
   * </pre>
   *
   * <code>repeated .api.v0alpha.HttpReq preliminary_requests = 2 [json_name = "preliminaryRequests"];</code>
   */
  java.util.List<? extends com.tcn.cloud.api.api.v0alpha.HttpReqOrBuilder> 
      getPreliminaryRequestsOrBuilderList();
  /**
   * <pre>
   * the requests to make, in order, to access priliminary data needed
   * to make the bulk data action part of the entrypoint.
   * the user is expected to specify which values need to be saved
   * in the HttpReq.named_response_values map.
   * </pre>
   *
   * <code>repeated .api.v0alpha.HttpReq preliminary_requests = 2 [json_name = "preliminaryRequests"];</code>
   */
  com.tcn.cloud.api.api.v0alpha.HttpReqOrBuilder getPreliminaryRequestsOrBuilder(
      int index);

  /**
   * <pre>
   * this request is expected to return records that can be parsed by
   * the file template each time it is called.
   * if no termination case is specified, then we terminate after the first run.
   * </pre>
   *
   * <code>.api.v0alpha.PaginatedHttpRequest paginated_request = 4 [json_name = "paginatedRequest"];</code>
   * @return Whether the paginatedRequest field is set.
   */
  boolean hasPaginatedRequest();
  /**
   * <pre>
   * this request is expected to return records that can be parsed by
   * the file template each time it is called.
   * if no termination case is specified, then we terminate after the first run.
   * </pre>
   *
   * <code>.api.v0alpha.PaginatedHttpRequest paginated_request = 4 [json_name = "paginatedRequest"];</code>
   * @return The paginatedRequest.
   */
  com.tcn.cloud.api.api.v0alpha.PaginatedHttpRequest getPaginatedRequest();
  /**
   * <pre>
   * this request is expected to return records that can be parsed by
   * the file template each time it is called.
   * if no termination case is specified, then we terminate after the first run.
   * </pre>
   *
   * <code>.api.v0alpha.PaginatedHttpRequest paginated_request = 4 [json_name = "paginatedRequest"];</code>
   */
  com.tcn.cloud.api.api.v0alpha.PaginatedHttpRequestOrBuilder getPaginatedRequestOrBuilder();

  /**
   * <pre>
   * the file template that can parse the paginated data
   * </pre>
   *
   * <code>string file_template_id = 5 [json_name = "fileTemplateId"];</code>
   * @return The fileTemplateId.
   */
  java.lang.String getFileTemplateId();
  /**
   * <pre>
   * the file template that can parse the paginated data
   * </pre>
   *
   * <code>string file_template_id = 5 [json_name = "fileTemplateId"];</code>
   * @return The bytes for fileTemplateId.
   */
  com.google.protobuf.ByteString
      getFileTemplateIdBytes();

  /**
   * <pre>
   * The name of this process. -YYYYMMDD will be attached.
   * If empty, defaults to web-entrypoint-&lt;now&gt;.
   * If scheduled through the lms-api, the element name will be used if left
   * blank
   * </pre>
   *
   * <code>string name = 7 [json_name = "name"];</code>
   * @return The name.
   */
  java.lang.String getName();
  /**
   * <pre>
   * The name of this process. -YYYYMMDD will be attached.
   * If empty, defaults to web-entrypoint-&lt;now&gt;.
   * If scheduled through the lms-api, the element name will be used if left
   * blank
   * </pre>
   *
   * <code>string name = 7 [json_name = "name"];</code>
   * @return The bytes for name.
   */
  com.google.protobuf.ByteString
      getNameBytes();

  /**
   * <pre>
   * the cron string, just like sftp_import process
   * </pre>
   *
   * <code>string cron = 19 [json_name = "cron"];</code>
   * @return The cron.
   */
  java.lang.String getCron();
  /**
   * <pre>
   * the cron string, just like sftp_import process
   * </pre>
   *
   * <code>string cron = 19 [json_name = "cron"];</code>
   * @return The bytes for cron.
   */
  com.google.protobuf.ByteString
      getCronBytes();

  /**
   * <pre>
   * Specifies the timezone to be used by the cron
   * </pre>
   *
   * <code>string timezone = 20 [json_name = "timezone"];</code>
   * @return The timezone.
   */
  java.lang.String getTimezone();
  /**
   * <pre>
   * Specifies the timezone to be used by the cron
   * </pre>
   *
   * <code>string timezone = 20 [json_name = "timezone"];</code>
   * @return The bytes for timezone.
   */
  com.google.protobuf.ByteString
      getTimezoneBytes();

  /**
   * <pre>
   * if false, the cron will not put events in the queue when triggered
   * </pre>
   *
   * <code>bool enabled = 21 [json_name = "enabled"];</code>
   * @return The enabled.
   */
  boolean getEnabled();

  /**
   * <pre>
   * how many pages we should save before aggregating the data and sending downstream
   * default is 100. Max is 10000.
   * If a termination state hasn't been reached, the event will be re-queued and continue
   * where it left off.
   * </pre>
   *
   * <code>int64 flush_page_count = 22 [json_name = "flushPageCount"];</code>
   * @return The flushPageCount.
   */
  long getFlushPageCount();

  /**
   * <pre>
   * how much total elapsed time (in minutes) we want to wait before flushing records.
   * if total time spent aggregating the data goes over this many minutes, we will flush
   * the current records downstream.
   * default is 20. Max is 120. Min is 1.
   * If a termination state hasn't been reached, the event will be re-queued and continue
   * where it left off.
   * </pre>
   *
   * <code>int64 flush_minute_count = 23 [json_name = "flushMinuteCount"];</code>
   * @return The flushMinuteCount.
   */
  long getFlushMinuteCount();

  /**
   * <pre>
   * if true, we will switch to processing mode when we have enough records to flush
   * even if we haven't downloaded all the pages yet.
   * after the current records are flushed, we switch back to downloading the remaining records.
   * If false (default), we download all the pages before we start processing any records.
   * </pre>
   *
   * <code>bool flush_during_check = 24 [json_name = "flushDuringCheck"];</code>
   * @return The flushDuringCheck.
   */
  boolean getFlushDuringCheck();
}
